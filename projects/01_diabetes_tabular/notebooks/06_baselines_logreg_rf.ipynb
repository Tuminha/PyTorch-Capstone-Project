{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models: Logistic Regression & Random Forest",
    "",
    "## \ud83c\udfaf Concept Primer",
    "Baselines sanity-check your preprocessing and provide a performance floor. If a neural net doesn't beat Logistic Regression, investigate why.",
    "",
    "**Model 1:** Logistic Regression (linear, interpretable)  ",
    "**Model 2:** Random Forest (non-linear, feature importance)",
    "",
    "Expected: Train both models, evaluate on validation set, compare metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccb Objectives",
    "1. Train Logistic Regression with class weights",
    "2. Train Random Forest with hyperparameter tuning",
    "3. Evaluate both on validation set",
    "4. Compare metrics (Accuracy, Precision, Recall, F1, ROC-AUC)",
    "5. Visualize confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u2705 Acceptance Criteria",
    "- [ ] Logistic Regression trained and evaluated",
    "- [ ] Random Forest trained and evaluated",
    "- [ ] Metrics table comparing both models",
    "- [ ] Confusion matrices plotted",
    "- [ ] Best baseline identified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 1: Import libraries",
    "# from sklearn.linear_model import LogisticRegression",
    "# from sklearn.ensemble import RandomForestClassifier",
    "# from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score",
    "# import matplotlib.pyplot as plt",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Logistic Regression Baseline",
    "",
    "### TODO 2: Train Logistic Regression",
    "",
    "**Parameters:** Use class_weight='balanced' to handle imbalance  ",
    "**Expected:** Fit on X_train, y_train; predict on X_val"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 2: Train Logistic Regression",
    "# lr = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)",
    "# lr.fit(X_train, y_train)",
    "# y_pred_lr = lr.predict(X_val)",
    "# y_proba_lr = lr.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf32 Random Forest Baseline",
    "",
    "### TODO 3: Train Random Forest",
    "",
    "**Parameters:** n_estimators=100, max_depth=10, class_weight='balanced'  ",
    "**Expected:** Fit on X_train, y_train; predict on X_val"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 3: Train Random Forest",
    "# rf = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42)",
    "# rf.fit(X_train, y_train)",
    "# y_pred_rf = rf.predict(X_val)",
    "# y_proba_rf = rf.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Evaluate Baselines",
    "",
    "### TODO 4: Compute metrics for both models",
    "",
    "**Metrics:** Accuracy, Precision, Recall, F1, ROC-AUC  ",
    "**Use:** classification_report and roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 4: Evaluate models",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score",
    "# ",
    "# metrics_lr = {",
    "#     'accuracy': accuracy_score(y_val, y_pred_lr),",
    "#     'precision': precision_score(y_val, y_pred_lr),",
    "#     'recall': recall_score(y_val, y_pred_lr),",
    "#     'f1': f1_score(y_val, y_pred_lr),",
    "#     'roc_auc': roc_auc_score(y_val, y_proba_lr)",
    "# }",
    "# ",
    "# metrics_rf = {",
    "#     'accuracy': accuracy_score(y_val, y_pred_rf),",
    "#     'precision': precision_score(y_val, y_pred_rf),",
    "#     'recall': recall_score(y_val, y_pred_rf),",
    "#     'f1': f1_score(y_val, y_pred_rf),",
    "#     'roc_auc': roc_auc_score(y_val, y_proba_rf)",
    "# }",
    "# ",
    "# print(\"Logistic Regression:\", metrics_lr)",
    "# print(\"Random Forest:\", metrics_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\udd14 Reflection",
    "1. Which baseline performs better? Why?",
    "2. What patterns do you see in confusion matrices?",
    "3. Are baselines good enough for your use case?",
    "4. What should the PyTorch model beat?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your reflection:**",
    "",
    "*Write here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccc Summary",
    "\u2705 Baselines trained and evaluated  ",
    "\u2705 Metrics compared  ",
    "\u2705 Ready for PyTorch model",
    "",
    "**Next:** `07_pytorch_ffn_build_train.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Splits\n",
    "\n",
    "## üéØ Concept Primer\n",
    "\n",
    "Preprocessing transforms raw features into ML-ready format. **Critical rule:** Fit scalers/encoders ONLY on training data, then transform val/test to prevent leakage.\n",
    "\n",
    "### Preprocessing Steps\n",
    "1. **Encode categoricals** ‚Äî One-Hot or Ordinal encoding\n",
    "2. **Scale continuous** ‚Äî StandardScaler (mean=0, std=1) or MinMaxScaler (0-1)\n",
    "3. **Split data** ‚Äî Train (70%) / Val (15%) / Test (15%), stratified by target\n",
    "4. **Handle imbalance** ‚Äî Class weights, oversampling, or threshold tuning\n",
    "\n",
    "**Expected outputs:** X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. Encode categorical features (One-Hot or Ordinal)\n",
    "2. Scale continuous features using StandardScaler\n",
    "3. Split into train/val/test (70/15/15 stratified)\n",
    "4. Choose an imbalance handling strategy\n",
    "5. Verify shapes and dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Acceptance Criteria\n",
    "\n",
    "You'll know you're done when:\n",
    "- [ ] All categoricals encoded\n",
    "- [ ] Continuous features scaled\n",
    "- [ ] Data split into train/val/test\n",
    "- [ ] Imbalance strategy chosen and documented\n",
    "- [ ] Shapes printed: X_train.shape, y_train.shape, etc.\n",
    "- [ ] No leakage (transformers fit only on train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import torch\n",
    "\n",
    "df = pd.read_csv(\"../../../datasets/diabetes_BRFSS2015.csv\")\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "numeric_cols = ['bmi', 'genhlth', 'menthlth', 'physhlth']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Separate Features and Target\n",
    "\n",
    "### TODO 2: Split data into X and y\n",
    "\n",
    "**Expected:**\n",
    "- X: All columns except `diabetes_binary`\n",
    "- y: Only `diabetes_binary`\n",
    "\n",
    "**Shapes:** X will be (N, D) where D = number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2: Separate features and target\n",
    "# X = df.drop('diabetes_binary', axis=1)\n",
    "# y = df['diabetes_binary']\n",
    "# print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Handle Imbalance\n",
    "\n",
    "### TODO 3: Choose imbalance strategy\n",
    "\n",
    "**Options:**\n",
    "1. **Class weights** ‚Äî Weight loss function by class frequency\n",
    "2. **Oversampling** ‚Äî SMOTE or RandomOverSampler (on train only!)\n",
    "3. **Threshold tuning** ‚Äî Adjust decision threshold at inference\n",
    "\n",
    "**Decision:** Choose one and document why in reflection.\n",
    "\n",
    "**Check imbalance:**\n",
    "```python\n",
    "y.value_counts(normalize=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3: Check imbalance\n",
    "# print(y.value_counts(normalize=True))\n",
    "\n",
    "# If using class weights:\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "# class_weight_dict = {0: class_weights[0], 1: class_weights[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Encode Categoricals\n",
    "\n",
    "### TODO 4: Apply One-Hot encoding\n",
    "\n",
    "**Columns to encode:** Binary features (already 0/1) and ordinal features\n",
    "\n",
    "**Options:**\n",
    "- OneHotEncoder: Creates separate columns for each category\n",
    "- Keep it simple: Most columns are already numeric!\n",
    "\n",
    "**Expected:** After encoding, all features should be numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4: Encode categoricals (if needed)\n",
    "# If you have string categoricals:\n",
    "# ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "# X_encoded = ohe.fit_transform(X[['categorical_col']])\n",
    "# X_encoded_df = pd.DataFrame(X_encoded, columns=ohe.get_feature_names_out())\n",
    "# X = pd.concat([X.drop('categorical_col', axis=1), X_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Scale Continuous Features\n",
    "\n",
    "### TODO 5: Apply StandardScaler\n",
    "\n",
    "**Fit on train only!** Then transform val/test.\n",
    "\n",
    "**Features to scale:** BMI, MentHlth, PhysHlth, Age (if numeric)\n",
    "\n",
    "**Process:**\n",
    "1. Split data first\n",
    "2. Fit scaler on X_train\n",
    "3. Transform X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5: Scale features\n",
    "# Split first\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Then scale\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_val_scaled = scaler.transform(X_val)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrames\n",
    "# X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "# X_val = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    "# X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Verify Splits\n",
    "\n",
    "### TODO 6: Print shapes and check dtypes\n",
    "\n",
    "**Expected outputs:**\n",
    "- X_train: (N_train, D)\n",
    "- y_train: (N_train,)\n",
    "- Similar for val and test\n",
    "- All should be numeric (float or int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 6: Verify splits\n",
    "# print(f\"Train: X={X_train.shape}, y={y_train.shape}\")\n",
    "# print(f\"Val: X={X_val.shape}, y={y_val.shape}\")\n",
    "# print(f\"Test: X={X_test.shape}, y={y_test.shape}\")\n",
    "# print(f\"\\nDtypes:\\n{X_train.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§î Reflection\n",
    "\n",
    "1. **Imbalance strategy:** Which did you choose? Why?\n",
    "2. **Scaler choice:** StandardScaler vs MinMaxScaler? Why?\n",
    "3. **Split strategy:** Why 70/15/15? Is test set large enough?\n",
    "4. **Leakage check:** Are you sure no val/test info leaked into training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your reflection:**\n",
    "\n",
    "*Write your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Summary\n",
    "\n",
    "‚úÖ **Encoded:** Categoricals converted to numeric  \n",
    "‚úÖ **Scaled:** Continuous features standardized  \n",
    "‚úÖ **Split:** Train/val/test created  \n",
    "‚úÖ **Balanced:** Imbalance strategy applied  \n",
    "‚úÖ **Ready for next step:** Train baseline models\n",
    "\n",
    "**Next notebook:** `06_baselines_logreg_rf.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Feed-Forward Network",
    "",
    "## \ud83c\udfaf Concept Primer",
    "Tabular FFN: X \u2192 [Linear\u2192ReLU\u2192Dropout]\u00d7k \u2192 Linear \u2192 logit",
    "",
    "**Architecture:** Input (D features) \u2192 Hidden(s) \u2192 Output (1 logit)  ",
    "**Loss:** BCEWithLogitsLoss (numerically stable)  ",
    "**Training:** Adam optimizer, early stopping, validation monitoring",
    "",
    "Expected shapes: X_train [B, D] \u2192 output [B, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccb Objectives",
    "1. Build TabularFFN class",
    "2. Setup training loop with BCEWithLogitsLoss",
    "3. Implement validation monitoring",
    "4. Add early stopping",
    "5. Save best model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u2705 Acceptance Criteria",
    "- [ ] TabularFFN model defined",
    "- [ ] Training loop runs 20-50 epochs",
    "- [ ] Validation loss tracked",
    "- [ ] Best weights saved",
    "- [ ] Training/val loss plots created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 1: Import libraries",
    "# import torch",
    "# import torch.nn as nn",
    "# import torch.optim as optim",
    "# from torch.utils.data import TensorDataset, DataLoader",
    "# import numpy as np",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfd7\ufe0f Build TabularFFN Model",
    "",
    "### TODO 2: Define TabularFFN class",
    "",
    "**Architecture:**",
    "- Input layer: D features",
    "- Hidden layers: [128, 64] with ReLU",
    "- Dropout: 0.3",
    "- Output layer: 1 logit",
    "",
    "**Expected:** Subclass nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 2: Define model",
    "# class TabularFFN(nn.Module):",
    "#     def __init__(self, input_dim, hidden_sizes=[128, 64], dropout=0.3):",
    "#         super(TabularFFN, self).__init__()",
    "#         # TODO: Define layers",
    "#         # self.fc1 = nn.Linear(input_dim, hidden_sizes[0])",
    "#         # self.relu1 = nn.ReLU()",
    "#         # self.dropout1 = nn.Dropout(dropout)",
    "#         # ... add more layers",
    "#         ",
    "#     def forward(self, x):",
    "#         # TODO: Forward pass",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd04 Prepare Data",
    "",
    "### TODO 3: Convert to PyTorch tensors",
    "",
    "**Expected:** FloatTensor for features, FloatTensor for labels  ",
    "**Shapes:** X shape [N, D], y shape [N]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 3: Convert to tensors",
    "# X_train_tensor = torch.FloatTensor(X_train.values)",
    "# y_train_tensor = torch.FloatTensor(y_train.values)",
    "# X_val_tensor = torch.FloatTensor(X_val.values)",
    "# y_val_tensor = torch.FloatTensor(y_val.values)",
    "# ",
    "# train_dataset = TensorDataset(X_train_tensor, y_train_tensor)",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Training Loop",
    "",
    "### TODO 4: Implement training loop",
    "",
    "**Components:**",
    "- Model initialization",
    "- Loss function: BCEWithLogitsLoss",
    "- Optimizer: Adam (lr=1e-3)",
    "- Training loop with model.train() / model.eval()",
    "- Validation loop",
    "- Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 4: Training loop",
    "# model = TabularFFN(input_dim=X_train.shape[1])",
    "# criterion = nn.BCEWithLogitsLoss()",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)",
    "# ",
    "# best_val_loss = float('inf')",
    "# patience = 5",
    "# epochs_no_improve = 0",
    "# ",
    "# for epoch in range(50):",
    "#     # Training phase",
    "#     model.train()",
    "#     train_loss = 0",
    "#     for batch_X, batch_y in train_loader:",
    "#         optimizer.zero_grad()",
    "#         outputs = model(batch_X).squeeze()",
    "#         loss = criterion(outputs, batch_y)",
    "#         loss.backward()",
    "#         optimizer.step()",
    "#         train_loss += loss.item()",
    "#     ",
    "#     # Validation phase",
    "#     model.eval()",
    "#     with torch.no_grad():",
    "#         val_outputs = model(X_val_tensor).squeeze()",
    "#         val_loss = criterion(val_outputs, y_val_tensor).item()",
    "#     ",
    "#     # Early stopping logic",
    "#     if val_loss < best_val_loss:",
    "#         best_val_loss = val_loss",
    "#         best_model_state = model.state_dict().copy()",
    "#         epochs_no_improve = 0",
    "#     else:",
    "#         epochs_no_improve += 1",
    "#     ",
    "#     if epochs_no_improve >= patience:",
    "#         print(f\"Early stopping at epoch {epoch}\")",
    "#         break",
    "#     ",
    "#     print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\udd14 Reflection",
    "1. Did training converge? How many epochs?",
    "2. Did NN beat baselines? By how much?",
    "3. Any overfitting? (train loss << val loss)",
    "4. Why BCEWithLogitsLoss over Sigmoid+BCELoss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your reflection:**",
    "",
    "*Write here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccc Summary",
    "\u2705 PyTorch model built and trained  ",
    "\u2705 Validation monitoring active  ",
    "\u2705 Best weights saved  ",
    "\u2705 Ready for final evaluation",
    "",
    "**Next:** `08_evaluation_and_conclusions.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Notes - Diabetes Tabular\n",
    "\n",
    "## Template for Reflection\n",
    "\n",
    "Use this notebook to log your progress, insights, and challenges throughout the project.\n",
    "\n",
    "### Entry Template\n",
    "- **Date:** YYYY-MM-DD\n",
    "- **Goal:** What were you trying to accomplish?\n",
    "- **What clicked:** What made sense today?\n",
    "- **What confused me:** What was unclear?\n",
    "- **One change for next time:** What would you do differently?\n",
    "- **Next experiment:** What will you try next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìì Project 01: Diabetes Prediction - Complete Lab Notes\n",
    "\n",
    "## ‚úÖ Project Status: COMPLETE\n",
    "\n",
    "**Duration:** ~10 hours  \n",
    "**Dataset:** BRFSS 2015 (253,680 samples, 22 features)  \n",
    "**Problem:** Trinary classification (No Diabetes, Prediabetes, Diabetes)  \n",
    "**Best Model:** PyTorch FFN - **71.7% accuracy**, F1 macro: **0.4799**\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Final Results Comparison\n",
    "\n",
    "| Model | Accuracy | F1 Weighted | F1 Macro | Class 0 F1 | Class 1 F1 | Class 2 F1 |\n",
    "|-------|----------|-------------|-----------|------------|------------|------------|\n",
    "| Logistic Regression | 64.4% | 0.7194 | 0.4287 | 0.82 | ~0.00 | 0.47 |\n",
    "| Random Forest | 67.9% | 0.7336 | 0.4289 | 0.83 | ~0.00 | 0.46 |\n",
    "| **PyTorch FFN ‚≠ê** | **71.7%** | **0.7368** | **0.4799** | **0.84** | **0.13** | **0.57** |\n",
    "\n",
    "**Key Achievement:** PyTorch model is the ONLY model to successfully learn the minority Prediabetes class.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Notebook-by-Notebook Reflections\n",
    "\n",
    "### Notebook 01: Project Goals and Data\n",
    "**Date:** October 2025  \n",
    "**Goal:** Define problem statement and success metrics\n",
    "\n",
    "**What Clicked:**\n",
    "- Clear problem definition: Trinary classification (No Diabetes, Prediabetes, Diabetes)\n",
    "- Understanding that class imbalance would be a major challenge\n",
    "- Setting realistic success metrics (Macro F1 ‚â• 0.60, ROC-AUC ‚â• 0.75)\n",
    "\n",
    "**Key Decisions:**\n",
    "- Focus on macro-averaged metrics to account for class imbalance\n",
    "- Prioritize per-class performance, especially for minority classes\n",
    "- Plan for interpretability (feature importance analysis)\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook 02: Load and Inspect\n",
    "**Goal:** Load data and understand its structure\n",
    "\n",
    "**What Clicked:**\n",
    "- Dataset confirmed as trinary classification (not binary as initially expected!)\n",
    "- **84% No Diabetes, 14% Diabetes, 2% Prediabetes** - severe imbalance\n",
    "- No missing values (excellent data quality)\n",
    "- 18 object columns need encoding\n",
    "\n",
    "**Key Insights:**\n",
    "- Prediabetes class (~2%) will be extremely challenging to learn\n",
    "- Need stratified sampling for train/val/test splits\n",
    "- Class weights or resampling will be essential\n",
    "\n",
    "**What Confused Me:**\n",
    "- Initial surprise about trinary classification vs. binary\n",
    "- Uncertainty about whether to collapse Prediabetes into Diabetes class\n",
    "\n",
    "**Decision:**\n",
    "- Keep trinary classification to preserve clinical distinction between conditions\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook 03: Cleaning\n",
    "**Goal:** Clean data and handle outliers\n",
    "\n",
    "**What Clicked:**\n",
    "- Understanding that categorical columns should stay as objects for proper encoding LATER\n",
    "- BMI outliers (>60) are physiologically unrealistic ‚Üí capped at 60\n",
    "- MentHlth and PhysHlth distributions (0-30 days) are naturally zero-inflated, not errors\n",
    "\n",
    "**Key Decisions:**\n",
    "- Kept categorical columns as objects (not converting to integers prematurely)\n",
    "- Capped BMI at 60 (575 cases affected)\n",
    "- Preserved MentHlth/PhysHlth distributions (zeros are valid \"no bad days\" responses)\n",
    "- GenHlth verified as valid 1-5 scale\n",
    "\n",
    "**What I Learned:**\n",
    "- Domain knowledge matters: zero values in health measures aren't missing data\n",
    "- Outlier handling requires clinical context, not just statistical thresholds\n",
    "- Premature encoding can limit flexibility in later preprocessing\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook 04: EDA and Visualization\n",
    "**Goal:** Explore relationships between features and target\n",
    "\n",
    "**What Clicked:**\n",
    "- **GenHlth ‚Üî PhysHlth correlation (0.52)** - makes sense clinically\n",
    "- **MentHlth ‚Üî PhysHlth correlation (0.35)** - mental/physical health connection\n",
    "- BMI distributions clearly separate: No Diabetes (lower) vs. Diabetes/Prediabetes (higher)\n",
    "- General health ratings worsen progressively: No Diabetes (~2) ‚Üí Prediabetes (~3) ‚Üí Diabetes (~3.5-4)\n",
    "\n",
    "**Surprising Finding:**\n",
    "- Prediabetes shows HIGHEST physical health burden (median ~3 days)\n",
    "- More pronounced than Diabetes group\n",
    "\n",
    "**Data Leakage Concerns Identified:**\n",
    "- `genhlth` and `physhlth` may be partially outcomes (not pure predictors)\n",
    "- Could inflate performance estimates\n",
    "- Decision: Keep them but document limitation\n",
    "\n",
    "**Recommended Features for Modeling:**\n",
    "- BMI, age, exercise, fruits/veggies (lifestyle)\n",
    "- General health, physical health, mental health\n",
    "- Sex, education, income (demographic)\n",
    "- High BP, high cholesterol, stroke history (medical history)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 05: Preprocessing, Splits, and Balance\n",
    "**Goal:** Prepare data for modeling with proper encoding, scaling, and splitting\n",
    "\n",
    "**What Clicked:**\n",
    "- **Split FIRST, then encode/scale** to prevent data leakage\n",
    "- 70/15/15 train/val/test split with stratification\n",
    "- Different encoding strategies for different variable types:\n",
    "  - Binary (Yes/No) ‚Üí 0/1\n",
    "  - Ordinal (age, education, income) ‚Üí OrdinalEncoder preserving order\n",
    "  - Nominal (sex) ‚Üí Manual mapping\n",
    "  - Numeric (BMI, health measures) ‚Üí StandardScaler\n",
    "\n",
    "**Critical Learning: Fit on Train Only!**\n",
    "- `OrdinalEncoder.fit(X_train)` then `transform(X_train, X_val, X_test)`\n",
    "- `StandardScaler.fit(X_train[numeric_cols])` then `transform` all splits\n",
    "- **This prevents data leakage from validation/test into training**\n",
    "\n",
    "**Class Weight Computation:**\n",
    "- Computed balanced class weights: {0: 0.396, 1: 18.26, 2: 2.39}\n",
    "- Class 1 (Prediabetes) weight is **46x higher** than Class 0\n",
    "- Tells loss function to pay more attention to rare class\n",
    "\n",
    "**What Confused Me Initially:**\n",
    "- When to split vs. when to encode\n",
    "- Why fit scalers only on train data\n",
    "- How `compute_class_weight('balanced')` works\n",
    "\n",
    "**Resolution:**\n",
    "- Split FIRST to establish train/val/test boundaries\n",
    "- Fit transformers only on train to prevent leakage\n",
    "- Class weights inversely proportional to class frequencies\n",
    "\n",
    "**Key Decision:**\n",
    "- Save preprocessed data to pickle file for use in later notebooks\n",
    "- Includes X_train, X_val, X_test, y_train, y_val, y_test, class_weight_dict\n",
    "\n",
    "**Final Feature Count:** 21 features, all numeric and ready for modeling\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook 06: Baseline Models (LR & RF)\n",
    "**Goal:** Train classical ML baselines to establish performance targets\n",
    "\n",
    "**What Clicked:**\n",
    "- **Logistic Regression:** 64.4% accuracy, F1 weighted: 0.7194\n",
    "- **Random Forest:** 67.9% accuracy, F1 weighted: 0.7336 (better)\n",
    "- Both models **completely fail** on Prediabetes (F1 ~0.00)\n",
    "\n",
    "**First Major Error Encountered:**\n",
    "- `ValueError: Target is multiclass but average='binary'`\n",
    "- **Cause:** `precision_score`, `recall_score`, `f1_score` default to `average='binary'`\n",
    "- **Fix:** Add `average='weighted'` or `average='macro'` for multi-class\n",
    "\n",
    "**Second Error:**\n",
    "- `AxisError: axis 1 is out of bounds for array of dimension 1`\n",
    "- **Cause:** Used `y_proba_lr = lr.predict_proba(X_val)[:, 1]` (slicing for binary)\n",
    "- **Fix:** Remove `[:, 1]` for multi-class (need all 3 class probabilities)\n",
    "\n",
    "**Understanding Metrics:**\n",
    "- **F1 Weighted:** Accounts for class imbalance by weighting each class by support\n",
    "- **F1 Macro:** Simple average across classes (treats all classes equally)\n",
    "- **ROC-AUC OVR:** One-vs-Rest strategy for multi-class ROC-AUC\n",
    "\n",
    "**Key Insight from Confusion Matrices:**\n",
    "- Main confusion: Diabetes ‚Üî No Diabetes (~1,300 misclassifications)\n",
    "- Prediabetes almost entirely missed (predicted as No Diabetes)\n",
    "- Class weights help but aren't enough for severe imbalance\n",
    "\n",
    "**Realistic PyTorch Goal Set:**\n",
    "- Target: 70-75% accuracy, F1 macro: 0.50-0.60\n",
    "- Stretch goal: Non-zero F1 for Prediabetes class\n",
    "\n",
    "**What I Learned:**\n",
    "- Baseline models establish \"beating random\" threshold\n",
    "- Severe imbalance (2%) is extremely hard even with class weights\n",
    "- Multi-class metrics require different parameters than binary\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 07: PyTorch FFN Build and Train üöÄ\n",
    "**Goal:** Build PyTorch neural network from scratch and train it\n",
    "\n",
    "**This was the MOST EDUCATIONAL notebook - learned PyTorch mechanics line-by-line!**\n",
    "\n",
    "#### Part 1: Building the `TabularFFN` Class\n",
    "\n",
    "**What I Learned (Line-by-Line):**\n",
    "\n",
    "1. **Class Definition:**\n",
    "   ```python\n",
    "   class TabularFFN(nn.Module):\n",
    "       def __init__(self, in_features, out_features):\n",
    "           super().__init__()  # MUST call parent __init__\n",
    "   ```\n",
    "   - Always inherit from `nn.Module`\n",
    "   - `super().__init__()` initializes PyTorch machinery\n",
    "\n",
    "2. **Layers in `__init__`:**\n",
    "   ```python\n",
    "   self.fc1 = nn.Linear(21, 256)   # 21 input features\n",
    "   self.fc2 = nn.Linear(256, 128)\n",
    "   self.fc3 = nn.Linear(128, 64)\n",
    "   self.fc4 = nn.Linear(64, 3)     # 3 output classes\n",
    "   self.dropout = nn.Dropout(0.3)\n",
    "   ```\n",
    "   - Layers are defined ONCE in `__init__`\n",
    "   - Each layer is stored as an attribute (`self.fc1`, etc.)\n",
    "   - Dropout rate 0.3 = 30% of neurons dropped during training\n",
    "\n",
    "3. **Forward Pass:**\n",
    "   ```python\n",
    "   def forward(self, x):\n",
    "       x = self.fc1(x)\n",
    "       x = torch.relu(x)\n",
    "       x = self.dropout(x)\n",
    "       x = self.fc2(x)\n",
    "       x = torch.relu(x)\n",
    "       x = self.dropout(x)\n",
    "       x = self.fc3(x)\n",
    "       x = torch.relu(x)\n",
    "       x = self.dropout(x)\n",
    "       x = self.fc4(x)  # NO activation on final layer (logits)\n",
    "       return x\n",
    "   ```\n",
    "   - **ReLU applied AFTER each linear layer** (not before)\n",
    "   - Dropout applied after activation\n",
    "   - **Final layer returns logits (no softmax!)** - CrossEntropyLoss handles it\n",
    "\n",
    "**Key Insight:**\n",
    "- `__init__` = define layers ONCE\n",
    "- `forward` = apply layers in sequence to data\n",
    "- Final layer outputs **logits** (raw scores), not probabilities\n",
    "\n",
    "---\n",
    "\n",
    "#### Part 2: Data Preparation (Tensors & DataLoaders)\n",
    "\n",
    "**What I Learned:**\n",
    "\n",
    "1. **Convert to Tensors:**\n",
    "   ```python\n",
    "   X_train_tensor = torch.FloatTensor(X_train.values)  # Features = FloatTensor\n",
    "   y_train_tensor = torch.LongTensor(y_train.values)   # Labels = LongTensor\n",
    "   ```\n",
    "   - Features MUST be `FloatTensor` (continuous)\n",
    "   - Labels MUST be `LongTensor` (integer class indices)\n",
    "\n",
    "2. **TensorDataset:**\n",
    "   ```python\n",
    "   train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "   ```\n",
    "   - Pairs features with labels\n",
    "   - Enables batching\n",
    "\n",
    "3. **DataLoader:**\n",
    "   ```python\n",
    "   train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "   ```\n",
    "   - Automatically creates batches\n",
    "   - `shuffle=True` for train, `False` for val/test\n",
    "   - Batch size 32 chosen as balance between speed and memory\n",
    "\n",
    "**Why DataLoaders?**\n",
    "- Automatic batching (don't manually slice arrays)\n",
    "- Memory efficient (load data in chunks)\n",
    "- Shuffling for better training\n",
    "\n",
    "---\n",
    "\n",
    "#### Part 3: Training Loop (The Heart of PyTorch!)\n",
    "\n",
    "**Line-by-Line Understanding:**\n",
    "\n",
    "1. **Model Instantiation:**\n",
    "   ```python\n",
    "   model = TabularFFN(21, 3)  # 21 inputs, 3 outputs\n",
    "   ```\n",
    "\n",
    "2. **Loss Function (CRITICAL FIX!):**\n",
    "   ```python\n",
    "   class_weights_tensor = torch.FloatTensor([0.396, 18.26, 2.39])\n",
    "   criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "   ```\n",
    "   - **Initial error:** Used `CrossEntropyLoss()` without weights ‚Üí model ignored minorities\n",
    "   - **Fix:** Added class weights ‚Üí model learned all 3 classes!\n",
    "\n",
    "3. **Optimizer (MAJOR LEARNING!):**\n",
    "   - **Initial attempt:** `optimizer = optim.Adam(model.parameters(), lr=0.001)`\n",
    "     - Result: Flat loss curve, no learning\n",
    "   - **Final solution:** `optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)`\n",
    "     - Result: Smooth convergence, excellent learning!\n",
    "   - **Key Insight:** SGD with momentum works better for imbalanced tabular data\n",
    "\n",
    "4. **Training Loop Structure:**\n",
    "   ```python\n",
    "   for epoch in range(n_epochs):\n",
    "       model.train()  # Set to training mode (enables dropout)\n",
    "       \n",
    "       for x_batch, y_batch in train_dataloader:\n",
    "           optimizer.zero_grad()              # 1. Clear old gradients\n",
    "           predictions = model(x_batch)       # 2. Forward pass\n",
    "           loss = criterion(predictions, y_batch)  # 3. Compute loss\n",
    "           loss.backward()                    # 4. Backward pass (compute gradients)\n",
    "           optimizer.step()                   # 5. Update weights\n",
    "   ```\n",
    "\n",
    "**The 5-Step Mantra (Memorized!):**\n",
    "1. `zero_grad()` - Clear old gradients\n",
    "2. `model(x)` - Forward pass\n",
    "3. `criterion()` - Compute loss\n",
    "4. `loss.backward()` - Compute gradients\n",
    "5. `optimizer.step()` - Update weights\n",
    "\n",
    "5. **Validation Phase:**\n",
    "   ```python\n",
    "   model.eval()  # Set to evaluation mode (disables dropout)\n",
    "   with torch.no_grad():  # Disable gradient computation\n",
    "       for x_val, y_val in val_dataloader:\n",
    "           predictions = model(x_val)\n",
    "           val_loss = criterion(predictions, y_val)\n",
    "   ```\n",
    "   - `model.eval()` turns off dropout and batch norm\n",
    "   - `torch.no_grad()` saves memory (no gradient tracking)\n",
    "\n",
    "---\n",
    "\n",
    "#### Results Analysis\n",
    "\n",
    "**Initial Attempt (Adam, lr=0.001, no class weights):**\n",
    "- Flat loss curve (~1.0 for all epochs)\n",
    "- Model predicted ONLY Class 0 (majority)\n",
    "- **Diagnosis:** Class imbalance + wrong optimizer\n",
    "\n",
    "**Final Solution (SGD + momentum, lr=0.0001, class weights):**\n",
    "- Train loss: 1.01 ‚Üí 0.91 (10% improvement)\n",
    "- Val loss: 0.95 ‚Üí 0.90 (smooth convergence)\n",
    "- Convergence at ~epoch 5, plateau at ~epoch 25\n",
    "- **No overfitting** (train/val gap < 0.02)\n",
    "\n",
    "**Architecture:**\n",
    "- 21 ‚Üí 256 ‚Üí 128 ‚Üí 64 ‚Üí 3\n",
    "- Dropout 0.3 throughout\n",
    "- Total: 4 layers (deeper than initial 3-layer attempt)\n",
    "\n",
    "**What Made It Work:**\n",
    "1. Class weights in loss function\n",
    "2. SGD with momentum instead of Adam\n",
    "3. Lower learning rate (0.0001 vs. 0.001)\n",
    "4. Deeper architecture (4 layers vs. 3)\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Learnings from Notebook 07\n",
    "\n",
    "**Technical:**\n",
    "- PyTorch class structure (`__init__` vs. `forward`)\n",
    "- Tensor types matter (`FloatTensor` vs. `LongTensor`)\n",
    "- DataLoader mechanics and batching\n",
    "- Training loop 5-step pattern\n",
    "- Validation loop with `eval()` and `no_grad()`\n",
    "- Model saving (`state_dict` vs. full checkpoint)\n",
    "\n",
    "**Conceptual:**\n",
    "- Logits vs. probabilities vs. predicted classes\n",
    "- Why CrossEntropyLoss includes softmax internally\n",
    "- Dropout is ONLY active during training\n",
    "- Learning rate has MASSIVE impact\n",
    "- Optimizer choice matters for different problems\n",
    "\n",
    "**Debugging:**\n",
    "- Flat loss curves = something fundamentally wrong\n",
    "- Check class predictions (are all classes being predicted?)\n",
    "- Hyperparameters can make or break training\n",
    "- SGD ‚â† Adam (different use cases)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 08: Evaluation and Conclusions\n",
    "**Goal:** Evaluate PyTorch model on test set and compare to baselines\n",
    "\n",
    "#### Loading and Evaluation Process\n",
    "\n",
    "**What I Learned:**\n",
    "\n",
    "1. **Loading Trained Models:**\n",
    "   ```python\n",
    "   model = TabularFFN(21, 3)\n",
    "   model.load_state_dict(torch.load(\"../models/diabetes_ffn_best.pth\"))\n",
    "   model.eval()\n",
    "   ```\n",
    "   - **Initial error:** `model.load_state_dict(\"path\")` ‚Üí TypeError\n",
    "   - **Fix:** Use `torch.load()` first to read the file, then pass dict\n",
    "   - Must set `model.eval()` before evaluation\n",
    "\n",
    "2. **Evaluation Loop:**\n",
    "   ```python\n",
    "   with torch.no_grad():\n",
    "       all_predictions = []\n",
    "       all_true_labels = []\n",
    "       \n",
    "       for x_test, y_test in test_dataloader:\n",
    "           outputs = model(x_test)  # Returns logits\n",
    "           predicted_classes = torch.argmax(outputs, dim=1)  # Convert to class indices\n",
    "           all_predictions.extend(predicted_classes.tolist())\n",
    "           all_true_labels.extend(y_test.tolist())\n",
    "   ```\n",
    "   - `torch.argmax(outputs, dim=1)` converts logits ‚Üí predicted classes\n",
    "   - `dim=1` means \"find max along class dimension\"\n",
    "   - Collect predictions/labels across all batches\n",
    "\n",
    "3. **Metrics Calculation (Multi-Class):**\n",
    "   ```python\n",
    "   test_metrics = {\n",
    "       'accuracy': accuracy_score(all_true_labels, all_predictions),\n",
    "       'precision_weighted': precision_score(all_true_labels, all_predictions, average='weighted'),\n",
    "       'f1_weighted': f1_score(all_true_labels, all_predictions, average='weighted'),\n",
    "       'f1_macro': f1_score(all_true_labels, all_predictions, average='macro')\n",
    "   }\n",
    "   ```\n",
    "   - MUST specify `average='weighted'` or `average='macro'` for multi-class\n",
    "   - Weighted = accounts for class imbalance\n",
    "   - Macro = treats all classes equally\n",
    "\n",
    "---\n",
    "\n",
    "#### Final Results\n",
    "\n",
    "**PyTorch FFN Test Set Performance:**\n",
    "- **Accuracy: 71.7%** (7.3% better than LR, 3.8% better than RF)\n",
    "- **F1 Weighted: 0.7368** (best)\n",
    "- **F1 Macro: 0.4799** (best)\n",
    "- **Class 0 (No Diabetes) F1: 0.84** (excellent)\n",
    "- **Class 1 (Prediabetes) F1: 0.13** (only model with non-zero!)\n",
    "- **Class 2 (Diabetes) F1: 0.57** (21% better than baselines)\n",
    "\n",
    "**Model Comparison:**\n",
    "- **Winner: PyTorch FFN** across ALL metrics\n",
    "- Achieved stretch goal: non-zero F1 for Prediabetes\n",
    "- Exceeded initial target (70% accuracy, 0.50 F1 macro)\n",
    "\n",
    "---\n",
    "\n",
    "#### Confusion Matrix Analysis\n",
    "\n",
    "**Key Patterns:**\n",
    "- PyTorch correctly identifies **22,031 No Diabetes cases** (excellent specificity)\n",
    "- **3,716 Diabetes cases** correctly identified (good sensitivity)\n",
    "- Only **92/694 Prediabetes** correctly identified (13% recall - still very low)\n",
    "\n",
    "**Main Error Modes:**\n",
    "1. Diabetes ‚Üí No Diabetes: ~1,035 cases (false negatives - COSTLY!)\n",
    "2. Prediabetes ‚Üí No Diabetes: ~400 cases (false negatives - COSTLY!)\n",
    "3. No Diabetes ‚Üí Diabetes: ~2,732 cases (false positives - less costly)\n",
    "\n",
    "**Clinical Implication:**\n",
    "- False negatives (missing diabetes/prediabetes) = high-cost errors\n",
    "- Missed diagnoses lead to disease progression\n",
    "- Solution: Lower classification thresholds for Classes 1 & 2\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Reflections from Notebook 08\n",
    "\n",
    "**1. Which errors matter most in diabetes screening?**\n",
    "- **False negatives >> False positives** in cost\n",
    "- Missing diabetes = disease progresses, complications develop\n",
    "- False positive = unnecessary follow-up test (low risk, low cost)\n",
    "- **Recommendation:** Prioritize recall over precision\n",
    "\n",
    "**2. What threshold would you use in production?**\n",
    "- **NOT the default 0.5 threshold**\n",
    "- Proposed class-specific thresholds:\n",
    "  - Class 1 (Prediabetes): 0.2-0.3 (maximize recall)\n",
    "  - Class 2 (Diabetes): 0.35-0.4 (balance sensitivity/specificity)\n",
    "  - Class 0 (No Diabetes): 0.5+ (maintain specificity)\n",
    "- **Rationale:** Prediabetes is reversible ‚Üí early detection critical\n",
    "\n",
    "**3. What would you do differently next time?**\n",
    "1. Address class imbalance from Day 1 (SMOTE/ADASYN)\n",
    "2. More feature engineering (interactions: BMI √ó Age, etc.)\n",
    "3. Cross-validation instead of single train/val/test split\n",
    "4. Try different architectures (residual connections, batch norm)\n",
    "5. Formal threshold tuning with precision-recall curves\n",
    "6. SHAP/LIME for explainability early in process\n",
    "7. Weights & Biases for experiment tracking\n",
    "\n",
    "**4. How did this project advance your skills?**\n",
    "\n",
    "**Technical Skills:**\n",
    "- PyTorch fundamentals (Module, forward, training loop)\n",
    "- Multi-class classification mechanics\n",
    "- Data preprocessing pipeline (encoding, scaling, splitting)\n",
    "- Model evaluation (confusion matrices, per-class metrics)\n",
    "- Debugging (error messages ‚Üí root causes ‚Üí fixes)\n",
    "\n",
    "**Conceptual Skills:**\n",
    "- Class imbalance handling strategies\n",
    "- Clinical context in model evaluation\n",
    "- Threshold tuning implications\n",
    "- Data leakage prevention\n",
    "- Iterative hyperparameter tuning\n",
    "\n",
    "**Meta-Learning:**\n",
    "- **How to learn PyTorch** through line-by-line construction\n",
    "- Reading shapes as debugging signals\n",
    "- Understanding \"why\" behind every hyperparameter\n",
    "- Systematic troubleshooting (flat loss ‚Üí diagnose ‚Üí fix)\n",
    "- Building intuition through experimentation\n",
    "\n",
    "**Before this project:** Could follow tutorials but didn't understand mechanics  \n",
    "**After this project:** Can build, train, evaluate, and debug PyTorch models independently\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Top 10 Lessons Learned\n",
    "\n",
    "### 1. **Class Imbalance is HARD**\n",
    "- Even with class weights, 2% minority class is extremely difficult\n",
    "- PyTorch was the ONLY model to learn Prediabetes (F1: 0.13)\n",
    "- Future: Need SMOTE/ADASYN or focal loss for severe imbalance\n",
    "\n",
    "### 2. **Split First, Then Transform**\n",
    "- **Critical order:** Split ‚Üí Encode ‚Üí Scale\n",
    "- Fit transformers ONLY on train data to prevent leakage\n",
    "- `OrdinalEncoder.fit(X_train)` then `.transform()` all splits\n",
    "\n",
    "### 3. **Optimizer Choice Matters Massively**\n",
    "- Adam (lr=0.001) ‚Üí flat loss, no learning\n",
    "- SGD (lr=0.0001, momentum=0.9) ‚Üí smooth convergence, excellent results\n",
    "- **Lesson:** Different optimizers for different problems\n",
    "\n",
    "### 4. **Class Weights Are Essential for Imbalanced Data**\n",
    "- Without weights: Model predicts only majority class\n",
    "- With weights: Model learns all classes\n",
    "- Use `compute_class_weight('balanced')` or pass to loss function\n",
    "\n",
    "### 5. **Learning Rate Has Huge Impact**\n",
    "- lr=0.001 ‚Üí no learning (too high)\n",
    "- lr=0.0001 ‚Üí excellent convergence\n",
    "- **Rule:** Start small, increase gradually if needed\n",
    "\n",
    "### 6. **Multi-Class Metrics Require Different Parameters**\n",
    "- Binary defaults don't work: `average='binary'` ‚Üí Error\n",
    "- Must specify: `average='weighted'` or `average='macro'`\n",
    "- ROC-AUC needs: `multi_class='ovr'` for multi-class\n",
    "\n",
    "### 7. **Logits vs. Probabilities vs. Predicted Classes**\n",
    "- `model(x)` ‚Üí **logits** (raw scores)\n",
    "- `torch.softmax(logits, dim=1)` ‚Üí **probabilities**\n",
    "- `torch.argmax(logits, dim=1)` ‚Üí **predicted classes**\n",
    "- CrossEntropyLoss expects logits (applies softmax internally)\n",
    "\n",
    "### 8. **Data Shapes Are Debugging Gold**\n",
    "- Always check: `X_train.shape`, `y_proba.shape`, `predictions.shape`\n",
    "- Shape mismatches = first clue to bugs\n",
    "- `(N, 3)` for multi-class probabilities, NOT `(N,)` sliced\n",
    "\n",
    "### 9. **Clinical Context Changes Everything**\n",
    "- Accuracy isn't enough for healthcare\n",
    "- False negatives >> false positives in cost\n",
    "- Threshold tuning is essential for deployment\n",
    "- Domain knowledge guides feature engineering\n",
    "\n",
    "### 10. **Iterative Debugging is the Real Skill**\n",
    "- Flat loss ‚Üí check class predictions ‚Üí add class weights\n",
    "- Multi-class error ‚Üí check `average` parameter ‚Üí fix\n",
    "- Shape error ‚Üí check slicing ‚Üí remove `[:, 1]`\n",
    "- **Process:** Error ‚Üí Diagnose ‚Üí Hypothesize ‚Üí Fix ‚Üí Verify\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêõ Common Errors Encountered & Solutions\n",
    "\n",
    "### Error 1: `ValueError: Target is multiclass but average='binary'`\n",
    "**When:** Calculating precision/recall/F1 for multi-class problem  \n",
    "**Cause:** sklearn metrics default to `average='binary'`  \n",
    "**Fix:** Add `average='weighted'` or `average='macro'` parameter\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong\n",
    "precision_score(y_true, y_pred)\n",
    "\n",
    "# ‚úÖ Correct\n",
    "precision_score(y_true, y_pred, average='weighted')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Error 2: `AxisError: axis 1 is out of bounds for array of dimension 1`\n",
    "**When:** Computing ROC-AUC for multi-class with sliced probabilities  \n",
    "**Cause:** Used `y_proba = model.predict_proba(X)[:, 1]` (binary slicing)  \n",
    "**Fix:** Remove `[:, 1]` slicing; multi-class needs all probabilities\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong (binary pattern)\n",
    "y_proba_lr = lr.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# ‚úÖ Correct (multi-class pattern)\n",
    "y_proba_lr = lr.predict_proba(X_val)  # Shape: (N, 3)\n",
    "roc_auc_score(y_val, y_proba_lr, multi_class='ovr', average='weighted')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Error 3: `TypeError: Expected state_dict to be dict-like, got <class 'str'>`\n",
    "**When:** Loading PyTorch model weights  \n",
    "**Cause:** Passed file path string directly to `load_state_dict()`  \n",
    "**Fix:** Use `torch.load()` to read file first\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong\n",
    "model.load_state_dict(\"path/to/model.pth\")\n",
    "\n",
    "# ‚úÖ Correct\n",
    "model.load_state_dict(torch.load(\"path/to/model.pth\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Error 4: `ValueError: At least one array required as input`\n",
    "**When:** Calling `train_test_split(stratify=y)` without data  \n",
    "**Cause:** Forgot to pass `X` and `y` as positional arguments  \n",
    "**Fix:** Provide both features and target\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong\n",
    "train_test_split(stratify=y)\n",
    "\n",
    "# ‚úÖ Correct\n",
    "train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Error 5: Flat Loss Curve (No Learning)\n",
    "**When:** Training PyTorch model but loss stays flat  \n",
    "**Causes:**  \n",
    "1. No class weights for imbalanced data\n",
    "2. Wrong optimizer (Adam when SGD needed)\n",
    "3. Learning rate too high or too low\n",
    "\n",
    "**Diagnosis Steps:**\n",
    "1. Check if model predicts all same class: `np.unique(predictions)`\n",
    "2. Add class weights to loss function\n",
    "3. Try different optimizer (SGD vs. Adam)\n",
    "4. Adjust learning rate (try 0.0001, 0.001, 0.01)\n",
    "\n",
    "**Fix:**\n",
    "```python\n",
    "# Add class weights\n",
    "class_weights = torch.FloatTensor([0.396, 18.26, 2.39])\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Try SGD with momentum\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Error 6: `NameError: name 'ordinal_enc' is not defined`\n",
    "**When:** Using variable from previous notebook  \n",
    "**Cause:** Variables don't persist across notebooks  \n",
    "**Fix:** Save preprocessed data and load in next notebook\n",
    "\n",
    "```python\n",
    "# Save in notebook 05\n",
    "import pickle\n",
    "data_dict = {'X_train': X_train, 'y_train': y_train, ...}\n",
    "with open('preprocessed_data.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)\n",
    "\n",
    "# Load in notebook 06\n",
    "with open('preprocessed_data.pkl', 'rb') as f:\n",
    "    data_dict = pickle.load(f)\n",
    "X_train = data_dict['X_train']\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Error 7: Target Variable Still String Format\n",
    "**When:** Models fail because y is still \"No Diabetes\", not 0  \n",
    "**Cause:** Forgot to encode target before creating X and y  \n",
    "**Fix:** Map target to integers FIRST\n",
    "\n",
    "```python\n",
    "# ‚úÖ Correct order\n",
    "diabetes_map = {'No Diabetes': 0, 'Prediabetes': 1, 'Diabetes': 2}\n",
    "df['diabetes_trinary'] = df['diabetes'].map(diabetes_map)\n",
    "\n",
    "# THEN create X and y\n",
    "X = df.drop(['diabetes', 'diabetes_trinary'], axis=1)\n",
    "y = df['diabetes_trinary']  # Now it's integers 0, 1, 2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Error 8: `ValueError: could not convert string to float: 'Yes'`\n",
    "**When:** Computing correlation matrix with string columns  \n",
    "**Cause:** Trying to correlate non-numeric columns  \n",
    "**Fix:** Select only numeric columns first\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong\n",
    "df.corr()  # Includes object columns\n",
    "\n",
    "# ‚úÖ Correct\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numeric_df.corr()\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ PyTorch Training Loop - The 5-Step Mantra (MEMORIZED!)\n",
    "\n",
    "This is the core pattern for training ANY PyTorch model:\n",
    "\n",
    "```python\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # Enable dropout/batch norm\n",
    "    \n",
    "    for x_batch, y_batch in train_dataloader:\n",
    "        # Step 1: Clear old gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 2: Forward pass (get predictions)\n",
    "        predictions = model(x_batch)\n",
    "        \n",
    "        # Step 3: Compute loss\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        \n",
    "        # Step 4: Backward pass (compute gradients)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Step 5: Update weights\n",
    "        optimizer.step()\n",
    "```\n",
    "\n",
    "**Why this order?**\n",
    "1. `zero_grad()` - Gradients accumulate by default; clear them first\n",
    "2. `model(x)` - Run data through network to get predictions\n",
    "3. `criterion()` - Compare predictions to truth to get loss\n",
    "4. `loss.backward()` - Compute gradients via backpropagation\n",
    "5. `optimizer.step()` - Use gradients to update weights\n",
    "\n",
    "**Validation phase:**\n",
    "```python\n",
    "model.eval()  # Disable dropout/batch norm\n",
    "with torch.no_grad():  # Don't compute gradients (saves memory)\n",
    "    for x_val, y_val in val_dataloader:\n",
    "        predictions = model(x_val)\n",
    "        val_loss = criterion(predictions, y_val)\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Final Project Summary\n",
    "\n",
    "### What We Built\n",
    "- **Complete end-to-end ML pipeline:** Data inspection ‚Üí cleaning ‚Üí EDA ‚Üí preprocessing ‚Üí modeling ‚Üí evaluation\n",
    "- **Three models:** Logistic Regression, Random Forest, PyTorch Feed-Forward Network\n",
    "- **Best model:** PyTorch FFN with 71.7% accuracy, F1 macro 0.4799\n",
    "- **Unique achievement:** Only model to learn the minority Prediabetes class (2% of data)\n",
    "\n",
    "### Technical Skills Mastered\n",
    "\n",
    "**PyTorch Fundamentals:**\n",
    "- ‚úÖ Building custom `nn.Module` classes\n",
    "- ‚úÖ Implementing training loops from scratch\n",
    "- ‚úÖ Understanding forward/backward propagation\n",
    "- ‚úÖ Handling imbalanced data with class weights\n",
    "- ‚úÖ Saving and loading models\n",
    "- ‚úÖ Evaluation loops with `torch.no_grad()`\n",
    "\n",
    "**Data Preprocessing:**\n",
    "- ‚úÖ Stratified train/val/test splits\n",
    "- ‚úÖ Encoding strategies (binary, ordinal, nominal)\n",
    "- ‚úÖ StandardScaler with proper fit/transform pattern\n",
    "- ‚úÖ Data leakage prevention\n",
    "- ‚úÖ Saving/loading preprocessed data\n",
    "\n",
    "**Model Evaluation:**\n",
    "- ‚úÖ Multi-class metrics (weighted vs. macro)\n",
    "- ‚úÖ Confusion matrix interpretation\n",
    "- ‚úÖ Per-class performance analysis\n",
    "- ‚úÖ Clinical context in metric selection\n",
    "\n",
    "**Debugging & Troubleshooting:**\n",
    "- ‚úÖ Reading error messages and tracing root causes\n",
    "- ‚úÖ Using shapes for debugging\n",
    "- ‚úÖ Diagnosing flat loss curves\n",
    "- ‚úÖ Fixing multi-class metric errors\n",
    "\n",
    "### Conceptual Understanding\n",
    "\n",
    "**What I Now Understand:**\n",
    "1. **Class imbalance** is extremely challenging even with class weights\n",
    "2. **Optimizer choice** can make or break training\n",
    "3. **Learning rate** is often the most important hyperparameter\n",
    "4. **Data leakage** prevention requires careful fit/transform patterns\n",
    "5. **Clinical context** changes how we evaluate and deploy models\n",
    "6. **Threshold tuning** is essential for real-world deployment\n",
    "7. **Iterative debugging** is the core skill, not memorization\n",
    "\n",
    "---\n",
    "\n",
    "### What Worked Well\n",
    "\n",
    "‚úÖ **Line-by-line learning approach** - Building training loop step-by-step  \n",
    "‚úÖ **Systematic error fixing** - Not skipping errors, understanding root causes  \n",
    "‚úÖ **Baseline comparison** - Established \"beating random\" threshold  \n",
    "‚úÖ **Comprehensive reflections** - Documented decisions and learnings throughout  \n",
    "‚úÖ **Clinical context awareness** - Considered false negative costs  \n",
    "\n",
    "---\n",
    "\n",
    "### What I'd Do Differently\n",
    "\n",
    "**If starting over:**\n",
    "\n",
    "1. **Address imbalance earlier:** Apply SMOTE/ADASYN in notebook 05\n",
    "2. **More feature engineering:** Create interaction terms (BMI √ó Age)\n",
    "3. **Cross-validation:** Use 5-fold CV instead of single split\n",
    "4. **Experiment tracking:** Use Weights & Biases from the start\n",
    "5. **Explainability earlier:** SHAP analysis in notebook 06\n",
    "6. **Threshold tuning:** Formal precision-recall curve analysis\n",
    "7. **Architecture experiments:** Try residual connections, batch norm\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways for Future Projects\n",
    "\n",
    "1. **Start with baselines** - They're quick and establish minimum performance\n",
    "2. **Check data shapes religiously** - Prevents 90% of bugs\n",
    "3. **Use class weights** for imbalanced data (not optional!)\n",
    "4. **Try SGD before Adam** for tabular data\n",
    "5. **Save everything** - Preprocessed data, models, metrics\n",
    "6. **Document decisions** - Future you will thank present you\n",
    "7. **Understand \"why\"** - Don't just copy-paste code\n",
    "\n",
    "---\n",
    "\n",
    "### Personal Growth\n",
    "\n",
    "**Before Project 01:**\n",
    "- Could follow PyTorch tutorials\n",
    "- Didn't understand training loop mechanics\n",
    "- Struggled with multi-class metrics\n",
    "- No systematic debugging approach\n",
    "\n",
    "**After Project 01:**\n",
    "- Can build PyTorch models independently\n",
    "- Understand every line of training code\n",
    "- Confidently handle multi-class problems\n",
    "- Have systematic debugging workflow\n",
    "\n",
    "**Most Important:**\n",
    "- **Learned how to learn** PyTorch through line-by-line construction\n",
    "- **Built intuition** through experimentation and failures\n",
    "- **Developed debugging mindset** - errors are learning opportunities\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Ready for Next Challenge\n",
    "\n",
    "**Skills to apply in Project 02 (Medical Text):**\n",
    "- PyTorch fundamentals (Module, training loop, evaluation)\n",
    "- Class imbalance handling\n",
    "- Systematic debugging approach\n",
    "- Comprehensive reflection habit\n",
    "\n",
    "**New skills to learn:**\n",
    "- NLP preprocessing (tokenization, padding)\n",
    "- Transformers architecture\n",
    "- Sequence data handling\n",
    "- Text-specific evaluation metrics\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Reference Quick Links\n",
    "\n",
    "- [PyTorch Documentation](https://pytorch.org/docs/)\n",
    "- [sklearn Metrics Guide](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- [Class Imbalance Techniques](https://imbalanced-learn.org/)\n",
    "- [Project 01 Final README](../README.md)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Project Status: COMPLETE\n",
    "\n",
    "**All 8 notebooks finished with comprehensive reflections.**\n",
    "\n",
    "**Final Model:** PyTorch FFN  \n",
    "**Final Accuracy:** 71.7%  \n",
    "**Final F1 Macro:** 0.4799\n",
    "\n",
    "**Most Proud Of:** Being the only model to successfully learn the Prediabetes class! üéØ\n",
    "\n",
    "---\n",
    "\n",
    "*This lab notes document captures the complete learning journey through Project 01. It serves as a reference for future projects and a testament to the power of systematic, reflective learning.*\n",
    "\n",
    "**Next up:** Project 02 - Medical Text Classification üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entry 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date:** \n",
    "\n",
    "**Goal:** \n",
    "\n",
    "**What clicked:** \n",
    "\n",
    "**What confused me:** \n",
    "\n",
    "**One change for next time:** \n",
    "\n",
    "**Next experiment:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Transfer Learning Breakthrough (Project 03 Snapshot)\n",
    "- **Date:** 2025-11-09\n",
    "- **Goal:** Understand why transfer learning (ResNet-18) outperformed the scratch CNN on retinal DR classification.\n",
    "- **What clicked:** Pretrained Imagenet filters already capture retinal textures, so only the classifier head needs to learn severity boundaries. Macro-F1 jumped from 0.31 ‚Üí 0.65.\n",
    "- **What confused me:** Why severe/proliferative recall was previously zero even with class weights‚Äîturns out the scratch CNN never saw enough diverse patterns to generalise.\n",
    "- **One change for next time:** Start with a pretrained backbone sooner, then fine-tune deeper layers once the head converges.\n",
    "- **Next experiment:** Unfreeze the last ResNet block, add retina-specific augmentation (CLAHE, rotations), and test focal loss to tighten `moderate` vs `proliferative` separation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

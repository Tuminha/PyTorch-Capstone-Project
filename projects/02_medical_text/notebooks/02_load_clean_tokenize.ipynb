{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Clean & Tokenize",
    "",
    "## \ud83c\udfaf Concept Primer",
    "Text preprocessing: lowercase, remove punctuation, tokenize into words.",
    "",
    "**Expected:** Cleaned text, token lists, sentence length stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccb Objectives",
    "1. Lowercase all text",
    "2. Remove punctuation/digits",
    "3. Tokenize sentences into words",
    "4. Compute sentence length statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 1: Import libraries",
    "# import pandas as pd",
    "# import re",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\uddf9 Clean Text",
    "",
    "### TODO 2: Lowercase and remove punctuation",
    "",
    "**Expected:** Cleaned text without special characters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 2: Clean text",
    "# def clean_text(text):",
    "#     text = text.lower()",
    "#     text = re.sub(r'[^a-zA-Z\\s]', '', text)",
    "#     return text",
    "# ",
    "# df['text_clean'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd24 Tokenize",
    "",
    "### TODO 3: Split into words",
    "",
    "**Expected:** List of tokens per document"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 3: Tokenize",
    "# df['tokens'] = df['text_clean'].apply(lambda x: x.split())",
    "# df['token_count'] = df['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Length Statistics",
    "",
    "### TODO 4: Analyze sentence lengths",
    "",
    "**Questions:** Mean/median length? Need padding/truncation?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 4: Length stats",
    "# print(df['token_count'].describe())",
    "# plt.hist(df['token_count'], bins=50)",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\udd14 Reflection",
    "1. What's a good max length for padding?",
    "2. Any pre-processing issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your reflection:**",
    "",
    "*Write here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccc Summary",
    "\u2705 Text cleaned  ",
    "\u2705 Tokens created  ",
    "\u2705 Length stats computed",
    "",
    "**Next:** `03_vocab_encoding_padding.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
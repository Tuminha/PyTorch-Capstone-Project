{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Notes - Medical Text\n",
    "\n",
    "## Template for Reflection\n",
    "\n",
    "Use this notebook to log your progress, insights, and challenges throughout the project.\n",
    "\n",
    "### Entry Template\n",
    "- **Date:** YYYY-MM-DD\n",
    "- **Goal:** What were you trying to accomplish?\n",
    "- **What clicked:** What made sense today?\n",
    "- **What confused me:** What was unclear?\n",
    "- **One change for next time:** What would you do differently?\n",
    "- **Next experiment:** What will you try next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entry 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date:** \n",
    "\n",
    "**Goal:** \n",
    "\n",
    "**What clicked:** \n",
    "\n",
    "**What confused me:** \n",
    "\n",
    "**One change for next time:** \n",
    "\n",
    "## ðŸ§ª Lab Notes - Project 02: Medical Text Classification\n",
    "\n",
    "### ðŸ“Š Project Overview\n",
    "\n",
    "**Goal:** Build a medical specialty classifier for 16K+ medical Q&A pairs using PyTorch and transformers  \n",
    "**Duration:** ~2-3 weeks (November 2024)  \n",
    "**Final Result:** BioBERT model achieving **83.79% F1 Macro** on 13-class classification (2.16x better than baseline!)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ—ºï¸ Journey Summary\n",
    "\n",
    "This project took me from **unsupervised taxonomy construction** â†’ **baseline neural network** â†’ **state-of-the-art transformer** â†’ **production-ready model**.\n",
    "\n",
    "**Key milestones:**\n",
    "1. **Notebook 00:** Built specialty taxonomy using k-means clustering (ML-first approach)\n",
    "2. **Notebooks 01-03:** Created NLP preprocessing pipeline (tokenization, vocab, encoding)\n",
    "3. **Notebook 04:** Trained baseline classifier, discovered overfitting\n",
    "4. **Notebook 05:** Fine-tuned BioBERT (83.73% validation F1 in 1 epoch!)\n",
    "5. **Notebook 06:** Test evaluation revealed baseline collapse (39% F1) vs BioBERT excellence (84% F1)\n",
    "\n",
    "**Most important learning:** Transfer learning with domain-specific pre-trained models (BioBERT) is a game-changer for specialized tasks!\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ“ Overall Lessons Learned\n",
    "\n",
    "**1. Transfer Learning > Training from Scratch**  \n",
    "- BioBERT (pre-trained on PubMed): **83.79% F1**  \n",
    "- Baseline (trained from scratch): **38.73% F1**  \n",
    "- **2.16x improvement** from using pre-trained knowledge!\n",
    "\n",
    "**2. Overfitting is Sneaky**  \n",
    "- Validation metrics can mislead (baseline: 63% â†’ 39%)  \n",
    "- Train/val curves showed overfitting, but magnitude was hidden  \n",
    "- **Always evaluate on test set!**\n",
    "\n",
    "**3. Class Imbalance Requires Special Handling**  \n",
    "- Baseline failed completely on 3 rare classes (F1 = 0.00)  \n",
    "- BioBERT handled them better (F1 â‰¥ 0.42) due to pre-trained knowledge  \n",
    "- **Strategies:** Oversampling, class weights, focal loss, or just use transformers!\n",
    "\n",
    "**4. OOV Problem is Real**  \n",
    "- 48% of samples had unknown words in baseline vocab  \n",
    "- Medical terms like \"retinopathy\" â†’ `<UNK>` â†’ lost information  \n",
    "- **Subword tokenization (BERT) solves this!**\n",
    "\n",
    "**5. Proper Evaluation Pipelines Matter**  \n",
    "- Index-based splitting ensures fair comparison  \n",
    "- Per-class metrics reveal hidden weaknesses  \n",
    "- Visualizations make results interpretable  \n",
    "- **Professional ML engineering = trust in results**\n",
    "\n",
    "**6. Computational Constraints are Real**  \n",
    "- BioBERT on CPU: 2.5 hours/epoch (vs 5 min for baseline)  \n",
    "- GPU would be 100x faster (5-10 min total for 5 epochs)  \n",
    "- **Workarounds:** Sampling, progress tracking, early stopping  \n",
    "- **For production:** GPU access is essential\n",
    "\n",
    "**7. Simple Baselines Have Value**  \n",
    "- Despite terrible performance (39% F1), baseline:  \n",
    "  - âœ… Quantified improvement magnitude  \n",
    "  - âœ… Highlighted vocabulary limitations  \n",
    "  - âœ… Proved transformers aren't overkill  \n",
    "  - âœ… Trained in 5 minutes (vs 2.5 hours)  \n",
    "- **Always start with simple baselines!**\n",
    "\n",
    "**8. Documentation is Learning**  \n",
    "- Writing reflections forced me to understand *why* things worked  \n",
    "- README as portfolio showcase  \n",
    "- Visualizations communicate results effectively  \n",
    "- **Good documentation = proof of understanding!**\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸš€ Skills Acquired\n",
    "\n",
    "**NLP & Text Processing:**  \n",
    "- âœ… Text cleaning & preprocessing  \n",
    "- âœ… Tokenization (word-level & subword)  \n",
    "- âœ… Vocabulary building  \n",
    "- âœ… Text encoding & padding  \n",
    "- âœ… Handling OOV (Out-Of-Vocabulary) words\n",
    "\n",
    "**Unsupervised Learning:**  \n",
    "- âœ… K-means clustering  \n",
    "- âœ… Sentence embeddings (BioBERT)  \n",
    "- âœ… Hyperparameter selection (elbow curve, silhouette score)  \n",
    "- âœ… UMAP dimensionality reduction\n",
    "\n",
    "**Supervised Learning (PyTorch):**  \n",
    "- âœ… Building `nn.Module` classes  \n",
    "- âœ… Embedding layers  \n",
    "- âœ… Training loops (5-step mantra)  \n",
    "- âœ… Loss functions (`CrossEntropyLoss`)  \n",
    "- âœ… Optimizers (Adam, AdamW)  \n",
    "- âœ… Custom `Dataset` and `DataLoader` implementation\n",
    "\n",
    "**Transfer Learning & Transformers:**  \n",
    "- âœ… Hugging Face `transformers` library  \n",
    "- âœ… Pre-trained model loading (`AutoModel`, `AutoTokenizer`)  \n",
    "- âœ… Fine-tuning BERT models  \n",
    "- âœ… BERT input format (input_ids, attention_mask)\n",
    "\n",
    "**Model Evaluation:**  \n",
    "- âœ… Train/val/test splitting (stratified)  \n",
    "- âœ… Metrics: accuracy, precision, recall, F1 (macro/weighted)  \n",
    "- âœ… Per-class performance analysis  \n",
    "- âœ… Overfitting detection (train vs val curves)\n",
    "\n",
    "**ML Engineering:**  \n",
    "- âœ… Index-based splitting for fair comparison  \n",
    "- âœ… Model saving & loading (`torch.save`, `load_state_dict`)  \n",
    "- âœ… Progress tracking for long-running jobs  \n",
    "- âœ… CPU optimization strategies  \n",
    "- âœ… Reproducible pipelines (`random_state=42`)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’­ Personal Reflections\n",
    "\n",
    "**What Surprised Me Most:**  \n",
    "The magnitude of improvement from transfer learning! I expected BioBERT to be better, but **2.16x better** (116% relative improvement) was mind-blowing. The fact that 1 epoch of BioBERT (83.73%) crushed 12 epochs of baseline (63.01%) showed that pre-trained knowledge is irreplaceable.\n",
    "\n",
    "**Hardest Challenge:**  \n",
    "**CPU training BioBERT for 2.5 hours per epoch!** The \"32 minutes, 0 epochs\" moment was genuinely scaryâ€”I thought my code had crashed!\n",
    "\n",
    "**Proudest Moment:**  \n",
    "When test results showed **BioBERT: 83.79% F1 (same as validation!)** while **baseline collapsed to 38.73%**. This validated my entire pipeline and proved this is **production-ready work!** ðŸŽ‰\n",
    "\n",
    "**Most Valuable Lesson:**  \n",
    "**\"Always test on held-out data.\"** Baseline looked okay at 63% validation F1, but test revealed the truth (39% F1). The discipline of proper train/val/test splits saved me from shipping a terrible model!\n",
    "\n",
    "**Skills I'm Most Confident In Now:**  \n",
    "- âœ… PyTorch training loops (could write from memory!)  \n",
    "- âœ… Hugging Face transformers (comfortable fine-tuning any model)  \n",
    "- âœ… Proper ML evaluation (train/val/test, stratification, fair comparison)  \n",
    "- âœ… Overfitting detection and mitigation  \n",
    "- âœ… Professional documentation and visualization\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Future Improvements\n",
    "\n",
    "**Short-term:**  \n",
    "1. **Confusion matrix analysis:** Identify which specialty pairs BioBERT confuses most  \n",
    "2. **Error inspection:** Read 10-20 misclassified samples to understand failure modes  \n",
    "3. **Confidence thresholding:** Flag predictions with confidence < 0.7 for human review\n",
    "\n",
    "**Medium-term:**  \n",
    "1. **Hyperparameter tuning:** Try different learning rates, dropout rates, batch sizes  \n",
    "2. **Train for more epochs (with GPU):** Current 1 epoch â†’ 3-5 epochs (might reach 85-86%)  \n",
    "3. **Try other medical transformers:** ClinicalBERT, PubMedBERT, Bio_ClinicalBERT\n",
    "\n",
    "**Long-term:**  \n",
    "1. **Data augmentation:** Paraphrase with GPT, back-translation, expand to 50K+ samples  \n",
    "2. **Ensemble methods:** Combine BioBERT + ClinicalBERT + domain rules  \n",
    "3. **Deployment:** Build REST API, containerize, deploy to cloud\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ‰ Final Thoughts\n",
    "\n",
    "**Project 02: Medical Text Classification is COMPLETE!**\n",
    "\n",
    "From building a taxonomy with k-means, to training a baseline neural network, to fine-tuning a state-of-the-art transformer, this project covered the full spectrum of modern NLP.\n",
    "\n",
    "**The result:** A production-ready model (BioBERT, 83.79% F1) that can accurately route medical questions to appropriate specialties.\n",
    "\n",
    "**The learning:** Transfer learning, proper evaluation, and professional ML engineering.\n",
    "\n",
    "**The pride:** This is portfolio-worthy work that demonstrates real ML expertise! ðŸ†\n",
    "\n",
    "---\n",
    "\n",
    "**Date Completed:** November 5, 2024  \n",
    "**Signed:** Francisco Teixeira Barbosa (@Tuminha)  \n",
    "**Achievement Unlocked:** ðŸ… Medical NLP Engineer\n",
    "\n",
    "**This is portfolio-worthy work!** ðŸŽ‰ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

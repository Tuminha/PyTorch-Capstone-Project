{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Classifier",
    "",
    "## \ud83c\udfaf Concept Primer",
    "Simple baseline: mean-pooled word embeddings + Linear classifier.",
    "",
    "**Architecture:** Embedding \u2192 Mean Pool \u2192 Linear \u2192 Output  ",
    "**Expected:** Baseline performance to beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccb Objectives",
    "1. Create Embedding layer",
    "2. Mean-pool embeddings",
    "3. Add Linear classifier",
    "4. Train baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 1: Import libraries",
    "# import torch",
    "# import torch.nn as nn",
    "# import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfd7\ufe0f Build Baseline Model",
    "",
    "### TODO 2: Define baseline classifier",
    "",
    "**Expected:** Class with embedding + mean pool + linear"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 2: Define model",
    "# class BaselineClassifier(nn.Module):",
    "#     def __init__(self, vocab_size, embed_dim=100, num_classes=X):",
    "#         super().__init__()",
    "#         self.embedding = nn.Embedding(vocab_size, embed_dim)",
    "#         self.classifier = nn.Linear(embed_dim, num_classes)",
    "#     ",
    "#     def forward(self, x):",
    "#         # TODO: Embed \u2192 mean pool \u2192 classify",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Train Baseline",
    "",
    "### TODO 3: Training loop",
    "",
    "**Expected:** Train for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 3: Training",
    "# model = BaselineClassifier(vocab_size, num_classes=num_classes)",
    "# criterion = nn.CrossEntropyLoss()",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)",
    "# ",
    "# for epoch in range(10):",
    "#     # TODO: Training loop",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\udd14 Reflection",
    "1. Baseline F1 score?",
    "2. Ready for transformer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your reflection:**",
    "",
    "*Write here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccc Summary",
    "\u2705 Baseline trained  ",
    "\u2705 Performance recorded",
    "",
    "**Next:** `05_transformer_setup_train.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
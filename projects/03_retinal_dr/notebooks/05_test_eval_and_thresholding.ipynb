{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Evaluation & Thresholding",
    "",
    "## \ud83c\udfaf Concept Primer",
    "Final evaluation on test set, optional threshold tuning for screening use case.",
    "",
    "**Expected:** Complete metrics, confusion matrix, conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccb Objectives",
    "1. Load best model",
    "2. Evaluate on test set",
    "3. Plot confusion matrix",
    "4. Optional: threshold sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 1: Import libraries",
    "# import torch",
    "# from sklearn.metrics import classification_report, confusion_matrix",
    "# import matplotlib.pyplot as plt",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Test Evaluation",
    "",
    "### TODO 2: Final evaluation",
    "",
    "**Expected:** Test accuracy, F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 2: Evaluate",
    "# model.load_state_dict(best_model_state)",
    "# model.eval()",
    "# ",
    "# all_preds = []",
    "# all_labels = []",
    "# with torch.no_grad():",
    "#     for images, labels in test_loader:",
    "#         outputs = model(images)",
    "#         preds = outputs.argmax(1)",
    "#         all_preds.extend(preds.cpu().numpy())",
    "#         all_labels.extend(labels.cpu().numpy())",
    "# ",
    "# print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Confusion Matrix",
    "",
    "### TODO 3: Visualize confusion",
    "",
    "**Expected:** Heatmap showing class confusions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO 3: Confusion matrix",
    "# cm = confusion_matrix(all_labels, all_preds)",
    "# plt.figure(figsize=(10, 8))",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')",
    "# plt.xlabel('Predicted')",
    "# plt.ylabel('Actual')",
    "# plt.title('Confusion Matrix')",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\udd14 Reflection",
    "1. Worst confused classes?",
    "2. Screening vs diagnostics threshold?",
    "3. Next improvements?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your reflection:**",
    "",
    "*Write here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccc Summary",
    "\u2705 Test evaluation complete  ",
    "\u2705 Confusion matrix plotted  ",
    "\u2705 Project complete!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}